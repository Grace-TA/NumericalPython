{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IydfPV4sm89N"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/weymouth/NumericalPython/blob/main/TablesAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IydfPV4sm89N"
   },
   "source": [
    "# Data Tables and Analysis in Pandas\n",
    "\n",
    "A common task in engineering is to perform analysis on field data, experimental data, or even simulation data. Wth the growth of Machine Learning techniques, this is more and more important to the state of the art, and the size of these data sets has grown larger and more complex. \n",
    "\n",
    "As a very simple example, consider this (simplified) table summarizing the vehicles used at the [National Oceanography Center](https://www.noc.ac.uk/facilities/national-marine-equipment-pool)\n",
    "\n",
    "| vehicle | count | speed (m/s) | size (m) | working fluid | flow type |\n",
    "|-------|----------|-------|------|---------------|-----------|\n",
    "| quad rotors | 4 | 18 | 0.06 | air | turbulent |\n",
    "| slocum gliders | 9 | 0.4 | 2 | water | transitional |\n",
    "| autosubs | 12 | 1.5 | 3 | water | turbulent\n",
    "| wave drones | 2 | 0.5 | 0.4 | water | laminar\n",
    "\n",
    "The data consists of labels, counts, floats and categories. Since every element in a NumPy array has to be the same data type, each column would need to be it's own array - which clashes with the natural grouping in terms of observations. \n",
    "\n",
    "The [Pandas](https://pandas.pydata.org/pandas-docs/stable/getting_started/index.html) library introduces a new data type called a [data frame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) to hold tables of data like this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "bbCeS35Bmc6V",
    "outputId": "b0367351-42ba-487a-fccb-42c9bce7df9d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = [['quad rotors', 4, 18, 0.06, 'air', 'turbulent'],\n",
    "        ['slocum gliders', 9, 0.4, 2, 'water', 'transitional'],\n",
    "        ['autosubs', 12, 1.5, 3, 'water', 'turbulent'],\n",
    "        ['wave drones', 2, 0.5, 0.4, 'water', 'laminar']]\n",
    "names = ['vehicle', 'count', 'speed (m/s)', 'size (m)', 'working fluid', 'flow type']\n",
    "table = pd.DataFrame(data,columns = names)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above `import`ed Pandas using the nickname `np` and used the method `DataFrame` to convert the data (a list of lists) and the column names (a list of strings) into a table. \n",
    "\n",
    "** Important notes: ** \n",
    "1. In practical usage, you would not *create* the data, you would *read* it. The data with the header would already be stored in a spreadsheet or a csv file. Pandas is great at [reading in data](https://pandas.pydata.org/pandas-docs/stable/getting_started/intro_tutorials/02_read_write.html#min-tut-02-read-write) from sources like this.\n",
    "2. Such data would typically contain many thousands of observations. Keeping this data [tidy](https://vita.had.co.nz/papers/tidy-data.pdf) and developing a reliable analysis pipeline is where the advantages of the programming approach to data science are most obvious.\n",
    "\n",
    "Once we have the data table, Pandas has a ton of built-in statistical operations to perform on it. For example, we can take the standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "2-EahoVLmu95",
    "outputId": "5b8f96f0-758a-4bbc-8870-c7f748fb987a"
   },
   "outputs": [],
   "source": [
    "table.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This only works for columns with a numerical data type. We can loop through the columns and get a description of each using the `describe` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "lbSne63UmlWv",
    "outputId": "d96ac8f6-d7fd-42c2-abec-562635fcaafb"
   },
   "outputs": [],
   "source": [
    "for col in table:\n",
    "    print('     ',col)           # column name\n",
    "    print(table[col].describe()) # descriptive stats\n",
    "    print('---------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this table is so short, we could also loop through *rows* using the row's `index`. The [loc`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html) method lets us access the data similar to a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in table.index:\n",
    "    print(table.loc[i])\n",
    "    print('--------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate plots very easily from the table. The `plot` function is a wrapper around `plt.plot()` and adds a legend with the column names automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.plot(xlabel='row');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying the table\n",
    "\n",
    "Let's quickly show how to add rows and columns to the table. First, add a row for the NOC's research ships by selecting an index which isn't filled yet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.loc[4] = ['ships',2,8,100,'water','turbulent']\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can overwrite a row this way as well.\n",
    "\n",
    "Lets add a Reynolds number $Re$ column to our table since it governs the transition from laminar to turbulent flow. Typically $Re$ 500k-1M marks the transition from laminar to turbulent, where $Re$ is defined as $\\text{speed} * \\text{size } / \\text{ kinematic viscosity}$ and the [kinematic viscosity](https://en.wikipedia.org/wiki/Viscosity) of water is $\\nu\\approx 10^{-6}~m^2/s$ and air is $\\nu\\approx 15\\times 10^{-6}~m^2/s$. \n",
    "\n",
    "We can use the NumPy [where](https://numpy.org/doc/stable/reference/generated/numpy.where.html) function to set the viscosity depending on the fluid and then apply the formula to get the Reynolds number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "table['kin visc (m*m/s)'] = np.where(table['working fluid']=='water', 1e-6, 15e-6)\n",
    "table['Re'] = table['speed (m/s)']*table['size (m)']/table['kin visc (m*m/s)']\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the $Re$ predicts the flow type nicely for all the vehicles except the quad rotor. The jets from the rotor are much faster and more turbulent than the vehicle speed implies, leading to the disparity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading and extensions\n",
    "\n",
    "For better or worse, we've barely scratched the surface of what is possible with Pandas. The [Pandas documentation website](https://pandas.pydata.org/pandas-docs/stable/index.html) is the best reference and it even has a whole list of more complete [community tutorials](https://pandas.pydata.org/pandas-docs/stable/getting_started/tutorials.html). **Overall** I think Pandas is great for keeping tables of heterogenous data organized, but it is a bit awkward and verbose to work with, and uses a lot of specialized syntax. If you can get away with a multi-dimensional array or two, you may find those easier to work with. \n",
    "\n",
    "Once you have your data in a DataFrame or an array, the next step is likely to be more advanced analysis. Here are a list of potential applications along with librabries which might help\n",
    " - Perform an FFT of a measured signal to determine its fundamental frequencies: [numpy.fft](https://numpy.org/doc/stable/reference/routines.fft.html)\n",
    " - Filter a signal or perform other signal processing: [scipy.signal](https://docs.scipy.org/doc/scipy/reference/signal.html)\n",
    " - Build a covariance table from an exterimental test matrix to identify the key parameters: [stats models](https://www.statsmodels.org/stable/index.html)\n",
    " - Fit a linear model to data and estimate the confidence on the model parameters: [stats models](https://www.statsmodels.org/stable/index.html)\n",
    " - Cluster a set of unlabeled experimental data into groups: [scikit-learn](https://scikit-learn.org/)\n",
    " - Fit a nonlinear regression model to data, controlling for model complexity: [scikit-learn](https://scikit-learn.org/)\n",
    " - Use a deep convolutional neural network to identify key features of seabed maps and images: [tensorflow](https://www.tensorflow.org/)\n",
    " - Use a deep autoencoder and automatic differentiation model turbulent flow: [tensorflow](https://www.tensorflow.org/)\n",
    "\n",
    "This list builds from commonplace to cutting edge research, and it's really amazing that Python can be used across the whole range. \n",
    "\n",
    "**Again, congratulations on completing this introduction to numerical python. Good luck in your studies and your engineering applications in the future!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "DataFrameCurveFitExample.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
